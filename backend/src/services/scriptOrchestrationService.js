// backend/src/services/scriptOrchestrationService.js

// This will be the refactored/renamed scriptGenerationService.js in the future.
// For now, it directly uses the existing service which handles LLM interaction.
const llmService = require('./scriptGenerationService');
const trendDiscoveryService = require('./trendDiscoveryService'); // Import TrendDiscoveryService 

class ScriptOrchestrationService {
  /**
   * Orchestrates the entire process of creating a video script.
   * @param {string} topic - The main topic for the script.
   * @param {Array<Object>} initialTrends - Optional. An array of initial trend objects.
   * @returns {Promise<string>} The generated script text.
   * @throws {Error} If script generation fails at any critical step.
   */
  async orchestrateScriptCreation(topic, initialTrends = []) {
    console.log(`[OrchestrationService] Starting script creation for topic: "${topic}"`);

    // Step 1: Trend Discovery & Enrichment
    console.log('[OrchestrationService] Invoking Trend Discovery Service...');
    let discoveredTrends = [];
    try {
      discoveredTrends = await trendDiscoveryService.discoverTrends(topic);
      console.log(`[OrchestrationService] Trend Discovery Service returned ${discoveredTrends.length} trends.`);
    } catch (error) {
      console.error('[OrchestrationService] Error during trend discovery:', error);
      // Decide how to handle trend discovery failure. For now, proceed with initialTrends if any.
      // In a real app, you might re-throw, or have a fallback.
    }

    // Combine initialTrends with discoveredTrends. For now, let's assume discoveredTrends are primary if available.
    // A more sophisticated merging strategy could be implemented later.
    const comprehensiveTrends = discoveredTrends.length > 0 ? discoveredTrends : initialTrends;
    console.log('[OrchestrationService] Trends prepared for LLM:', comprehensiveTrends);

    // Step 2: LLM Script Generation
    // The llmService (currently scriptGenerationService) is responsible for constructing
    // the appropriate prompt and interacting with the LLM.
    console.log('[OrchestrationService] Invoking LLM service for script generation...');
    let scriptText;
    try {
      scriptText = await llmService.generateScript(topic, comprehensiveTrends);
      console.log('[OrchestrationService] Script successfully generated by LLM service.');
    } catch (error) {
      console.error('[OrchestrationService] Error during LLM script generation:', error);
      // Re-throw the error to be handled by the controller or a higher-level error handler
      throw new Error(`Failed to generate script via LLM: ${error.message}`);
    }

    // Step 3: Post-processing (Placeholder)
    // Future enhancements could include formatting the script, adding standard intros/outros,
    // or other content modifications.
    console.log('[OrchestrationService] Script post-processing (placeholder).');

    // Step 4: Return the final script
    return scriptText;
  }
}

module.exports = new ScriptOrchestrationService();
